{
 "cells": [
  {
   "source": [
    "# IDL Homework 2\n",
    "\n",
    "Mikko Saukkoriipi, Sebastian Lampinen & Ville Kopio\n",
    "\n",
    "## Regularization\n",
    "\n",
    "This model uses Gaussian noise, early stopping and dropout. Random erasing of image data was also tested but due to the images being low resolution it only affected negatively to the results.\n",
    "\n",
    "## Optimization\n",
    "\n",
    "We tested three different optimization techniques\n",
    "\n",
    "- Stochastic gradient decent torch.optim.SGD\n",
    "- Adam torch.optim.Adam\n",
    "- Sparse Adam torch.optim.SparseAdam\n",
    "\n",
    "## Test accuracy\n",
    "\n",
    "Test accuracy of over 92 % was reached as shown in the cells bellow."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import statistics\n",
    "\n",
    "#--- hyperparameters ---\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 100\n",
    "LR = 0.0001\n",
    "\n",
    "#--- fixed constants ---\n",
    "NUM_CLASSES = 24\n",
    "DATA_DIR = '../data/sign_mnist_%s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "\n",
    "def load_dataset(dataset_name, shuffle=False, extra_transforms=[]):\n",
    "    common_transforms = [\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=0.5, std=0.5, inplace=True)\n",
    "    ]\n",
    "\n",
    "    dataset = datasets.ImageFolder(\n",
    "        DATA_DIR % dataset_name,\n",
    "        transform=transforms.Compose(common_transforms + extra_transforms)\n",
    "    )\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "train_loader = load_dataset('train', shuffle=True, extra_transforms=[AddGaussianNoise(0.1, 0.1),])\n",
    "dev_loader = load_dataset('dev')\n",
    "test_loader = load_dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- model ---\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Sequential 1: Convolution + batch normalization + ReLU + maxpooling\n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=28, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=28),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
    "        \n",
    "        # Sequential 2: Convolution + batch normalization + ReLU + maxpooling\n",
    "        self.seq2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=28, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Dropout(p=0.1))\n",
    "        \n",
    "        # Sequential 3: Linear + ReLU + Linear\n",
    "        self.seq3 = nn.Sequential(\n",
    "            nn.Linear(in_features=3136, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=512, out_features=NUM_CLASSES))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.seq1(x)\n",
    "        x = self.seq2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.seq3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cuda is available: False \n\n"
     ]
    }
   ],
   "source": [
    "#--- set up ---\n",
    "print(\"Cuda is available: {} \\n\".format(torch.cuda.is_available()))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping parameters initialization\n",
    "# Make empty dev lost list and add start values 0 to list\n",
    "# When done=True, then end training\n",
    "dev_loss_list = []\n",
    "train_loss_list = []\n",
    "dev_loss_list.append(100)\n",
    "dev_loss_list.append(100)\n",
    "dev_loss_list.append(100)\n",
    "done = False\n",
    "counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 | training acc 0.7904, loss 0.8500 | dev acc 0.8191, loss 0.5948\n"
     ]
    }
   ],
   "source": [
    "#--- training ---\n",
    "for epoch in range(N_EPOCHS):\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    total = len(train_loader.dataset)\n",
    "    \n",
    "    for batch_num, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        train_correct += (predicted == target).sum().item()\n",
    "        loss = loss_function(outputs, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss\n",
    "\n",
    "        print('Epoch %d | batch %d %% done' % (epoch + 1, 100 * (batch_num + 1) / len(train_loader),), end=\"\\r\")\n",
    "\n",
    "    train_loss_list.append(float(train_loss / len(train_loader)))\n",
    "\n",
    "    # -- Check development set accuracy and stop training if it start to decline\n",
    "    dev_loss = 0\n",
    "    dev_correct = 0\n",
    "    total = 0\n",
    "    for dev_batch_num, (dev_data, dev_target) in enumerate(dev_loader):\n",
    "        dev_data, dev_target = dev_data.to(device), dev_target.to(device)\n",
    "\n",
    "        dev_outputs = model(dev_data)\n",
    "        _, dev_predicted = torch.max(dev_outputs, 1)\n",
    "\n",
    "        dev_correct += (dev_predicted == dev_target).sum().item()\n",
    "        dev_loss += loss_function(dev_outputs, dev_target)\n",
    "    \n",
    "    dev_loss = dev_loss / len(dev_loader)\n",
    "    \n",
    "    # Save dev loss to list\n",
    "    dev_loss_list.append(dev_loss)\n",
    "\n",
    "    print('Epoch %d | training acc %.4f, loss %.4f | dev acc %.4f, loss %.4f' %\n",
    "            (epoch + 1,\n",
    "            train_correct / len(train_loader.dataset),\n",
    "            train_loss / len(train_loader),\n",
    "            dev_correct / len(dev_loader.dataset),\n",
    "            dev_loss))\n",
    "\n",
    "\n",
    "    # If the latest dev correct accuracy is smaller than the last 3 values, then end training\n",
    "    dev_last_three = dev_loss_list[-4:-1]\n",
    "    if dev_loss > max(dev_last_three):\n",
    "        print(\"Dev accuracy declining. Activate early stopping. \\n\")\n",
    "        done = True\n",
    "        break\n",
    "\n",
    "# Remove initialized first three values from dev_correct_list\n",
    "dev_loss_list = dev_loss_list[3:]\n",
    "\n",
    "# Plot dev correct\n",
    "plt.plot(dev_loss_list, label = \"Dev loss\")\n",
    "plt.plot(train_loss_list, label = \"Train loss\")\n",
    "plt.ylim((0, max(dev_loss_list+train_loss_list)+0.01))\n",
    "plt.title(\"Train and dev loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-100621c2beb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#--- test ---\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_num, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        outputs=model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        test_correct += (predicted == target).sum()\n",
    "        loss = loss_function(outputs, target)\n",
    "        test_loss += loss\n",
    "\n",
    "print(\"\\nTest accuracy %.2f %%\" % (100. * test_correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('3.8.6')",
   "language": "python",
   "name": "python38664bit386726142dc9582408698c2c8aa87fe6d21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}